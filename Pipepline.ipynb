{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#EXPLORE-DATA\" data-toc-modified-id=\"EXPLORE-DATA-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>EXPLORE DATA</a></span></li><li><span><a href=\"#ENCODE-THE-LABLES-AS-CATEGORICAL-VARIABLES\" data-toc-modified-id=\"ENCODE-THE-LABLES-AS-CATEGORICAL-VARIABLES-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ENCODE THE LABLES AS CATEGORICAL VARIABLES</a></span></li><li><span><a href=\"#COUNT-UNIQUE-LABELS\" data-toc-modified-id=\"COUNT-UNIQUE-LABELS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>COUNT UNIQUE LABELS</a></span></li><li><span><a href=\"#MEASURE-SUCCESS:-LOGLOSS\" data-toc-modified-id=\"MEASURE-SUCCESS:-LOGLOSS-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>MEASURE SUCCESS: LOGLOSS</a></span></li><li><span><a href=\"#2.-SETUP-A-TRAIN-TEST-SPLIT-IN-SKLEARN\" data-toc-modified-id=\"2.-SETUP-A-TRAIN-TEST-SPLIT-IN-SKLEARN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>2. SETUP A TRAIN-TEST-SPLIT IN SKLEARN</a></span></li><li><span><a href=\"#TRAIN-A-MODEL-WITH-LOGIT-REGRESSION\" data-toc-modified-id=\"TRAIN-A-MODEL-WITH-LOGIT-REGRESSION-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TRAIN A MODEL WITH LOGIT REGRESSION</a></span></li><li><span><a href=\"#USE-MODEL-TO-PREDICT-ON-HOLDOUT-DATA-AND-SUBMIT\" data-toc-modified-id=\"USE-MODEL-TO-PREDICT-ON-HOLDOUT-DATA-AND-SUBMIT-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>USE MODEL TO PREDICT ON HOLDOUT DATA AND SUBMIT</a></span></li><li><span><a href=\"#BAG_OF_WORD-IN-SKLEARN\" data-toc-modified-id=\"BAG_OF_WORD-IN-SKLEARN-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>BAG_OF_WORD IN SKLEARN</a></span></li><li><span><a href=\"#COMBINE-TEXT-COLUMNS-FOR-TOKENIZATION\" data-toc-modified-id=\"COMBINE-TEXT-COLUMNS-FOR-TOKENIZATION-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>COMBINE TEXT COLUMNS FOR TOKENIZATION</a></span></li><li><span><a href=\"#COMBINE-ALL-OF-THEM-INTO-PIPELINE\" data-toc-modified-id=\"COMBINE-ALL-OF-THEM-INTO-PIPELINE-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>COMBINE ALL OF THEM INTO PIPELINE</a></span></li><li><span><a href=\"#TRY-DIFFERENT-MODEL:-RANDOM-FOREST-AND-ADJUST-PARAMETER\" data-toc-modified-id=\"TRY-DIFFERENT-MODEL:-RANDOM-FOREST-AND-ADJUST-PARAMETER-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>TRY DIFFERENT MODEL: RANDOM FOREST AND ADJUST PARAMETER</a></span></li><li><span><a href=\"#4\" data-toc-modified-id=\"4-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>4</a></span></li><li><span><a href=\"#INTERACTION-MODELLING\" data-toc-modified-id=\"INTERACTION-MODELLING-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>INTERACTION MODELLING</a></span></li><li><span><a href=\"#HASHING\" data-toc-modified-id=\"HASHING-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>HASHING</a></span></li><li><span><a href=\"#PIPELINE-COMBINE-HASHING-+-INTERACTION\" data-toc-modified-id=\"PIPELINE-COMBINE-HASHING-+-INTERACTION-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>PIPELINE COMBINE HASHING + INTERACTION</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('TrainingData.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400277 entries, 134338 to 415831\n",
      "Data columns (total 25 columns):\n",
      "Function                  400277 non-null object\n",
      "Use                       400277 non-null object\n",
      "Sharing                   400277 non-null object\n",
      "Reporting                 400277 non-null object\n",
      "Student_Type              400277 non-null object\n",
      "Position_Type             400277 non-null object\n",
      "Object_Type               400277 non-null object\n",
      "Pre_K                     400277 non-null object\n",
      "Operating_Status          400277 non-null object\n",
      "Object_Description        375493 non-null object\n",
      "Text_2                    88217 non-null object\n",
      "SubFund_Description       306855 non-null object\n",
      "Job_Title_Description     292743 non-null object\n",
      "Text_3                    109152 non-null object\n",
      "Text_4                    53746 non-null object\n",
      "Sub_Object_Description    91603 non-null object\n",
      "Location_Description      162054 non-null object\n",
      "FTE                       126071 non-null float64\n",
      "Function_Description      342195 non-null object\n",
      "Facility_or_Department    53886 non-null object\n",
      "Position_Extra            264764 non-null object\n",
      "Total                     395722 non-null float64\n",
      "Program_Description       304660 non-null object\n",
      "Fund_Description          202877 non-null object\n",
      "Text_1                    292285 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 79.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134338</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206341</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>CONTRACTOR SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326408</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364634</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47683</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>TEACHER COVERAGE FOR TEACHER</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Function          Use          Sharing Reporting  \\\n",
       "134338     Teacher Compensation  Instruction  School Reported    School   \n",
       "206341                 NO_LABEL     NO_LABEL         NO_LABEL  NO_LABEL   \n",
       "326408     Teacher Compensation  Instruction  School Reported    School   \n",
       "364634  Substitute Compensation  Instruction  School Reported    School   \n",
       "47683   Substitute Compensation  Instruction  School Reported    School   \n",
       "\n",
       "       Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "134338     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "206341     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "326408  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "364634  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "47683   Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "         Operating_Status            Object_Description  \\\n",
       "134338  PreK-12 Operating                           NaN   \n",
       "206341      Non-Operating           CONTRACTOR SERVICES   \n",
       "326408  PreK-12 Operating  Personal Services - Teachers   \n",
       "364634  PreK-12 Operating             EMPLOYEE BENEFITS   \n",
       "47683   PreK-12 Operating  TEACHER COVERAGE FOR TEACHER   \n",
       "\n",
       "                    ...               Sub_Object_Description  \\\n",
       "134338              ...                                  NaN   \n",
       "206341              ...                                  NaN   \n",
       "326408              ...                                  NaN   \n",
       "364634              ...                                  NaN   \n",
       "47683               ...                                  NaN   \n",
       "\n",
       "       Location_Description  FTE     Function_Description  \\\n",
       "134338                  NaN  1.0                      NaN   \n",
       "206341                  NaN  NaN                 RGN  GOB   \n",
       "326408                  NaN  1.0                      NaN   \n",
       "364634                  NaN  NaN  UNALLOC BUDGETS/SCHOOLS   \n",
       "47683                   NaN  NaN              NON-PROJECT   \n",
       "\n",
       "       Facility_or_Department              Position_Extra      Total  \\\n",
       "134338                    NaN               KINDERGARTEN   50471.810   \n",
       "206341                    NaN                UNDESIGNATED   3477.860   \n",
       "326408                    NaN                     TEACHER  62237.130   \n",
       "364634                    NaN  PROFESSIONAL-INSTRUCTIONAL     22.300   \n",
       "47683                     NaN  PROFESSIONAL-INSTRUCTIONAL     54.166   \n",
       "\n",
       "                   Program_Description        Fund_Description  \\\n",
       "134338                    KINDERGARTEN            General Fund   \n",
       "206341   BUILDING IMPROVEMENT SERVICES                     NaN   \n",
       "326408           Instruction - Regular  General Purpose School   \n",
       "364634  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n",
       "47683    GENERAL HIGH SCHOOL EDUCATION                     NaN   \n",
       "\n",
       "                               Text_1  \n",
       "134338                            NaN  \n",
       "206341  BUILDING IMPROVEMENT SERVICES  \n",
       "326408                            NaN  \n",
       "364634            REGULAR INSTRUCTION  \n",
       "47683             REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109283</th>\n",
       "      <td>Professional Development</td>\n",
       "      <td>ISPD</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Instructional Coach</td>\n",
       "      <td>Other Compensation/Stipend</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>WORKSHOP PARTICIPANT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAFF DEV AND INSTR MEDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INST STAFF TRAINING SVCS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>STAFF DEV AND INSTR MEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102430</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF PART TIME EMPLOYEE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00431</td>\n",
       "      <td>TITLE II,D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>128.824985</td>\n",
       "      <td>INSTRUCTIONAL STAFF TRAINING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413949</th>\n",
       "      <td>Parent &amp; Community Relations</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Other</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARENT/TITLE I</td>\n",
       "      <td>4902.290000</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Schoolwide Schools</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433672</th>\n",
       "      <td>Library &amp; Media</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School on Central Budgets</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Librarian</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>EMPLOYEE BENEFITS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ED RESOURCE SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OFFICE/ADMINISTRATIVE SUPPORT</td>\n",
       "      <td>4020.290000</td>\n",
       "      <td>MEDIA SUPPORT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415831</th>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Poverty</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>Salaries And Wages For Substitute Professionals</td>\n",
       "      <td>...</td>\n",
       "      <td>Inservice Substitute Teachers Grant Funded</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>CERTIFIED SUBSTITUTE</td>\n",
       "      <td>46.530000</td>\n",
       "      <td>Accelerated Education</td>\n",
       "      <td>\"Title  Part A Improving Basic Programs\"</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Function          Use                    Sharing  \\\n",
       "109283      Professional Development         ISPD            Shared Services   \n",
       "102430       Substitute Compensation  Instruction            School Reported   \n",
       "413949  Parent & Community Relations     NO_LABEL            School Reported   \n",
       "433672               Library & Media  Instruction  School on Central Budgets   \n",
       "415831       Substitute Compensation  Instruction            School Reported   \n",
       "\n",
       "         Reporting Student_Type        Position_Type  \\\n",
       "109283  Non-School  Unspecified  Instructional Coach   \n",
       "102430      School  Unspecified           Substitute   \n",
       "413949      School     NO_LABEL                Other   \n",
       "433672  Non-School  Unspecified            Librarian   \n",
       "415831      School      Poverty           Substitute   \n",
       "\n",
       "                       Object_Type     Pre_K   Operating_Status  \\\n",
       "109283  Other Compensation/Stipend  NO_LABEL  PreK-12 Operating   \n",
       "102430    Base Salary/Compensation  NO_LABEL  PreK-12 Operating   \n",
       "413949                    NO_LABEL  NO_LABEL  PreK-12 Operating   \n",
       "433672                    Benefits  NO_LABEL  PreK-12 Operating   \n",
       "415831     Substitute Compensation  Non PreK  PreK-12 Operating   \n",
       "\n",
       "                                     Object_Description  \\\n",
       "109283                   WORKSHOP PARTICIPANT             \n",
       "102430                   SALARIES OF PART TIME EMPLOYEE   \n",
       "413949                                              NaN   \n",
       "433672                                EMPLOYEE BENEFITS   \n",
       "415831  Salaries And Wages For Substitute Professionals   \n",
       "\n",
       "                     ...                \\\n",
       "109283               ...                 \n",
       "102430               ...                 \n",
       "413949               ...                 \n",
       "433672               ...                 \n",
       "415831               ...                 \n",
       "\n",
       "                            Sub_Object_Description  \\\n",
       "109283                                         NaN   \n",
       "102430                                         NaN   \n",
       "413949                                         NaN   \n",
       "433672                                         NaN   \n",
       "415831  Inservice Substitute Teachers Grant Funded   \n",
       "\n",
       "                  Location_Description      FTE  \\\n",
       "109283  STAFF DEV AND INSTR MEDIA           NaN   \n",
       "102430                             NaN  0.00431   \n",
       "413949                             NaN  1.00000   \n",
       "433672            ED RESOURCE SERVICES      NaN   \n",
       "415831                         School       NaN   \n",
       "\n",
       "                  Function_Description      Facility_or_Department  \\\n",
       "109283  INST STAFF TRAINING SVCS                               NaN   \n",
       "102430                      TITLE II,D                         NaN   \n",
       "413949                             NaN                         NaN   \n",
       "433672                     NON-PROJECT                         NaN   \n",
       "415831                     Instruction  Instruction And Curriculum   \n",
       "\n",
       "                       Position_Extra        Total  \\\n",
       "109283                            NaN    48.620000   \n",
       "102430     PROFESSIONAL-INSTRUCTIONAL   128.824985   \n",
       "413949                 PARENT/TITLE I  4902.290000   \n",
       "433672  OFFICE/ADMINISTRATIVE SUPPORT  4020.290000   \n",
       "415831           CERTIFIED SUBSTITUTE    46.530000   \n",
       "\n",
       "                 Program_Description  \\\n",
       "109283                           NaN   \n",
       "102430  INSTRUCTIONAL STAFF TRAINING   \n",
       "413949                          Misc   \n",
       "433672        MEDIA SUPPORT SERVICES   \n",
       "415831         Accelerated Education   \n",
       "\n",
       "                                Fund_Description  \\\n",
       "109283            GENERAL FUND                     \n",
       "102430                                       NaN   \n",
       "413949                        Schoolwide Schools   \n",
       "433672                                       NaN   \n",
       "415831  \"Title  Part A Improving Basic Programs\"   \n",
       "\n",
       "                                Text_1  \n",
       "109283  STAFF DEV AND INSTR MEDIA       \n",
       "102430             INSTRUCTIONAL STAFF  \n",
       "413949                             NaN  \n",
       "433672             INSTRUCTIONAL STAFF  \n",
       "415831                  MISCELLANEOUS   \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 FTE         Total\n",
      "count  126071.000000  3.957220e+05\n",
      "mean        0.426794  1.310586e+04\n",
      "std         0.573576  3.682254e+05\n",
      "min        -0.087551 -8.746631e+07\n",
      "25%         0.000792  7.379770e+01\n",
      "50%         0.130927  4.612300e+02\n",
      "75%         1.000000  3.652662e+03\n",
      "max        46.800000  1.297000e+08\n"
     ]
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> there are 2 numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high variance in expenditures ('Total') makes sense (some purchases are cheap some are expensive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna(), bins = 500)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "plt.xlim([0,1])\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODE THE LABLES AS CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> 23 'object' type => inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 9 labels in datasets which are\n",
    "# https://www.drivendata.org/competitions/4/box-plots-for-education/page/15/#labels_list\n",
    "LABELS = ['Function',\n",
    " 'Object_Type',\n",
    " 'Operating_Status',\n",
    " 'Position_Type',\n",
    " 'Pre_K',\n",
    " 'Reporting',\n",
    " 'Sharing',\n",
    " 'Student_Type',\n",
    " 'Use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function            object\n",
       "Object_Type         object\n",
       "Operating_Status    object\n",
       "Position_Type       object\n",
       "Pre_K               object\n",
       "Reporting           object\n",
       "Sharing             object\n",
       "Student_Type        object\n",
       "Use                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the type for the labels\n",
    "df[LABELS].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> should change to 'category' for efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".astype() only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the .apply() method and provide a lambda function called categorize_label that applies .astype() to each column, x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Object_Type         category\n",
      "Operating_Status    category\n",
      "Position_Type       category\n",
      "Pre_K               category\n",
      "Reporting           category\n",
      "Sharing             category\n",
      "Student_Type        category\n",
      "Use                 category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT UNIQUE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEASURE SUCCESS: LOGLOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predictions will be probabilities for each label\n",
    "- log loss provides a steep penalty for predictions that are both wrong and confident\n",
    "- Better to be less confident than confident and wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logloss\n",
    "import numpy as np\n",
    "\n",
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\" Computes the logarithmic loss between predicted and\n",
    "        actual when these are 1D arrays.\n",
    "    \n",
    "        :param predicted: The predicted probabilities as floats between 0-1\n",
    "        :param actual: The actual binary labels. Either 0 or 1.\n",
    "        :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "              + (1 - actual)\n",
    "              * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define types of prediction\n",
    "actual_labels = np.array([ 1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])\n",
    "correct_confident = np.array([ 0.95,  0.95,  0.95,  0.95,  0.95,  0.05,  0.05,  0.05,  0.05,  0.05])\n",
    "correct_not_confident = np.array([ 0.65,  0.65,  0.65,  0.65,  0.65,  0.35,  0.35,  0.35,  0.35,  0.35])\n",
    "wrong_not_confident = np.array([ 0.35,  0.35,  0.35,  0.35,  0.35,  0.65,  0.65,  0.65,  0.65,  0.65])\n",
    "wrong_confident = np.array([ 0.05,  0.05,  0.05,  0.05,  0.05,  0.95,  0.95,  0.95,  0.95,  0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 1.5114254167193697\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SETUP A TRAIN-TEST-SPLIT IN SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Default train-test split not work because it not work with many target variable. Moreover, we could end up with labels in test set that never appear in training set \n",
    "- New function make sure at least min-count examples of each label appear in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function train-test-split for multiple labels\n",
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).all():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    # get 'min_count' sample from each column, concat the indice and then get the unique indices\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320222 non-null float64\n",
      "Total    320222 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 413949\n",
      "Data columns (total 2 columns):\n",
      "FTE      80055 non-null float64\n",
      "Total    80055 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 134338 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Use_Untracked Budget Set-Aside\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 206341 to 413949\n",
      "Columns: 104 entries, Function_Aides Compensation to Use_Untracked Budget Set-Aside\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN A MODEL WITH LOGIT REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier # Treats each column of y independently and fits a separate classifier for each of the columns\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE MODEL TO PREDICT ON HOLDOUT DATA AND SUBMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Holdout data: additional test set with hidden correct labels, only seen by holder of competition\n",
    "- Correct format: https://www.drivendata.org/competitions/4/page/15/#sub_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thanh Thanh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],\n",
    "                                                    prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score: 2.715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAG_OF_WORD IN SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "# [A-Za-z0-9]: alphanumeric character\n",
    "# +: one or moer\n",
    "# (?=\\\\s+): followed by (?=) one or more space\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINE TEXT COLUMNS FOR TOKENIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "- In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4757 tokens in the dataset\n",
      "There are 3284 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern: using any non-whitespace characters as a token \n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINE ALL OF THEM INTO PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "# FuntionTransformer creates an object with 'fit' and 'transform' method to used with pipeline\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Complete the pipeline: pl\n",
    "# only two high-level steps in your pipeline: preprocessing ('union') and model instantiation ('clf').\n",
    "numeric_pipeline = Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer()) # By default, the imputer transformer replaces NaNs with the mean value of the column.\n",
    "                ])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ])\n",
    "    \n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion( # FeatureUnion use allavailable features in 1 pipeline because pipeline steps for numeric and text can't follow each other, they must be at the same time\n",
    "            transformer_list = [\n",
    "                ('numeric_features', numeric_pipeline),\n",
    "                ('text_features', text_pipeline)\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n",
    "\n",
    "# Predict on holdout data\n",
    "predictions = pl.predict_proba(holdout)\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],\n",
    "                                                    prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY DIFFERENT MODEL: RANDOM FOREST AND ADJUST PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1,2))), # Include unigrams and bi-grams in the model to capture important information involving multiple tokens - e.g., ‘middle school\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k)) # Dimensional reduction use chi-sqaured test to select K best feature \n",
    "                ])) # http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()), # Scale the features\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "                \n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n",
    "\n",
    "# Predict on holdout data\n",
    "predictions = pl.predict_proba(holdout)\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],\n",
    "                                                    prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERACTION MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.\n",
    "- Eg: (English teacher for 2nd grade) and (2nd grade - budget for English teacher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction with Polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x = np.arange(6).reshape(3, 2)\n",
    "x\n",
    "interaction = PolynomialFeatures(degree = 2,\n",
    "                                 interaction_only=True,\n",
    "                                 include_bias=False)\n",
    "interaction.fit_transform(x)\n",
    "\n",
    "# Bias term allows model to have non-zero y value when x value is 0\n",
    "\n",
    "# Sparse interaction features: replacement for PolynomialFeatures since:\n",
    "    # The number of interaction terms grows exponentially => vectorizer saves memory by using sparse matrix -  a matrix that is comprised of mostly zero values\n",
    "    # PolynomialFeatures does not support sparse matrices => use SparseInteractions instead\n",
    "\n",
    "# Define SparseInteractions (dont need to understand)\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)    \n",
    "\n",
    "# SparseInteractions works like PolynomialFeatures\n",
    "SparseInteractions(degree=2).fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HASHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash function limits possible outputs, fixing array size (like a dictionary).\n",
    "hash_dict = {'and': 780, 'fluids': 354, 'fuel': 895, 'petro': 354, 'vend': 785}\n",
    "# => some text is hashed to the same value to make sure the number of featured is fixed => reduce number of features compared with CountVectorizer\n",
    "# Cons: there can be collisions: distinct tokens can be mapped to the same feature index.\n",
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())\n",
    "\n",
    "# Compare with CountVectorizer\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "vec_text = vec_alphanumeric.fit_transform(text_vector)\n",
    "vec_df = pd.DataFrame(vec_text.data)\n",
    "print(vec_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE COMBINE HASHING + INTERACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "                    \n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n",
    "\n",
    "# Predict on holdout data\n",
    "predictions = pl.predict_proba(holdout)\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],\n",
    "                                                    prefix_sep='__').columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
